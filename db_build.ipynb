{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3 as sql\n",
    "import numpy as np\n",
    "\n",
    "from functions import fetch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for the backtesting environment will come from Yahoo Finance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'C:\\\\Users\\\\William\\\\Downloads'\n",
    "path = '\\\\Downloads'\n",
    "print('https://finance.yahoo.com/lookup/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull files from downloads to save as pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "files = ['FB.csv', 'AAPL.csv', 'NFLX.csv', 'GOOG.csv', 'ES=F.csv']\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(path, file))\n",
    "    \n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "    df.sort_values('date', inplace=True)\n",
    "    df.drop('adj_close', axis=1, inplace=True)\n",
    "\n",
    "    if file == 'ES=F.csv':\n",
    "        name = 'sp500_df'\n",
    "    else:\n",
    "        name = file[:-4].lower() + '_df'\n",
    "    \n",
    "    dataframes[name] = df\n",
    "\n",
    "dataframes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop observations before 2009:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['aapl_df'] = dataframes['aapl_df'].loc[7078:].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['nflx_df'] = dataframes['nflx_df'].loc[1664:].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['goog_df'] = dataframes['goog_df'].loc[1100:].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['sp500_df'] = dataframes['sp500_df'].loc[2577:].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for building the db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sql(conn, all_dfs):\n",
    "\n",
    "    for name, df in all_dfs.items():\n",
    "\n",
    "        df.to_sql(name, con=conn, index=False, if_exists='replace')\n",
    "    \n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for querying/testing the db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(conn, name):\n",
    "    \n",
    "    c = conn.cursor()\n",
    "    \n",
    "    c.execute(f\"\"\"\n",
    "        SELECT * \n",
    "        FROM {name};\n",
    "        \"\"\")\n",
    "    \n",
    "    df = pd.DataFrame(c.fetchall(), columns=['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to wrap SQL functions in try-except clauses to avoid certain errors with the .db file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sql.connect('ticker_data.db')\n",
    "\n",
    "try:\n",
    "    build_sql(connection, dataframes)\n",
    "    #query(connection, 'fb_df')\n",
    "except Exception as e:\n",
    "    print('EXCEPTION', e)\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sql.connect('ticker_data.db')\n",
    "\n",
    "try:\n",
    "    query(connection, 'sp500_df')\n",
    "except Exception as e:\n",
    "    print('EXCEPTION', e)\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_data('fb_df').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
